# JAIInferenceSystem

## 项目背景
实现推理框架开发的全流程

## 技术要点
C++、CMake、Git、CUDA、单元测试、工厂模式、GEMM、OpenMp、GDB调试。

## 主要工作
1. 使用 ONNX 作为模型中间结构，来进行后续开发
2. 运用工厂模式，简化算子开发流程，提供统一接口完成 Conv2d、AdaptivePool、Linear、Silu 等算子实现，支持后续拓展更多算子
3. 数据处理模块：采用工厂方法模式，实现不同的模型的预处理方法
4. 编写单元测试验证推理准确性，保障框架稳定可靠。
5. 优化算子性能，支持 CPU 上的 OpenMp 多线程加速，部分算子支持 CUDA 加速，卷积算子支持 IM2COL+GEMM 加速
6. 内存优化模块：在模型进行推理时，对使用过的内存进行复用，减少内存开销
7. 计算图优化模块：完成常见的算子融合，对整个计算图进行优化
8. 提升框架开发效率采用引用计数法管理 Mat 类内存

## 项目成果
框架支持ResNet、YOLOV5等常见的神经网络的前向推理

## 支持的算子


## Benchmark


## 编译与运行

